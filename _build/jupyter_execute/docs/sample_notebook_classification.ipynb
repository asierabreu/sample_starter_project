{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8597bad9",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The task at hand is classification of terrain types from satellite images.\n",
    "We will use two different approaches:\n",
    "- A \"standard\" transfer learning approach where we will build a CNN using a base model (from Imagenet)\n",
    "- A \"bayesian\" approach where we will take into account uncertainty on the provided labels\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. [Data Inspection](#inspection) \n",
    "    - Loading\n",
    "    - Inspection\n",
    "    - Preprocessing\n",
    "2. [Modeling](#model-definition)\n",
    "    - Convolutional Neural Network\n",
    "    - Bayesian Neural Network\n",
    "3. [Prediction](#prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf4da4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Software install (as required)\n",
    "#!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e0c567",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd18374d",
   "metadata": {},
   "source": [
    "## Data Inspection <a name=\"inspection\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1179011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading : load the EuroSat dataset\n",
    "# 27000 Sentinel-2 satellite images covering 13 spectral bands. \n",
    "# Reference : https://github.com/phelber/eurosat\n",
    "\n",
    "# load train, test & validation splits into 60%, 20%,20% respectively\n",
    "(ds_train, ds_test, ds_valid), ds_info   = tfds.load(\n",
    "    \"eurosat\", \n",
    "    split=[\"train[:60%]\",\"train[60%:80%]\",\"train[80%:]\"],\n",
    "    as_supervised=True,\n",
    "    shuffle_files=True,\n",
    "    with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09980da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Info\n",
    "class_names = ds_info.features[\"label\"].names\n",
    "num_classes = ds_info.features[\"label\"].num_classes\n",
    "image_size  = ds_info.features[\"image\"]\n",
    "print('Total no. of classes : %d' %num_classes)\n",
    "print('Class labels  : %s' %class_names)\n",
    "print(\"Total examples: %d\" %(len(ds_valid)+len(ds_train)+len(ds_test)))\n",
    "print(\"Train set size: %d\" %len(ds_train)) \n",
    "print(\"Test set size : %d\" %len(ds_test))   \n",
    "print(\"Valid set size: %d\" %len(ds_valid))\n",
    "print(\"\")\n",
    "ds = ds_train.take(1)  # Only take a single example\n",
    "for image, label in ds: \n",
    "  print('image tensor shape: %s' %image.shape)\n",
    "  print('label tensor type: %s' %label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a few examples from the train dataset\n",
    "tfds.as_dataframe(ds_train.take(10), ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcee758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class balance check : is the dataset imbalanced?\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,6))\n",
    "\n",
    "labels, counts = np.unique(np.fromiter(ds_train.map(lambda x, y: y), np.int32), \n",
    "                       return_counts=True)\n",
    "ax.set_xlabel('Counts')\n",
    "ax.grid(True,ls='--')\n",
    "ax.set_title(\"Counts by type of terrain\");\n",
    "sns.barplot(x=counts, y=[class_names[l] for l in labels], label=\"Total\")\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a7ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, batch_size=64, shuffle_buffer_size=1000):\n",
    "  if cache:\n",
    "    if isinstance(cache, str):\n",
    "      ds = ds.cache(cache)\n",
    "    else:\n",
    "      ds = ds.cache()\n",
    "  # one-hot encode labels\n",
    "  ds = ds.map(lambda d: (d[\"image\"], tf.one_hot(d[\"label\"], num_classes)))\n",
    "  # shuffle the dataset\n",
    "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "  # Repeat forever\n",
    "  ds = ds.repeat()\n",
    "  # split to batches\n",
    "  ds = ds.batch(batch_size)\n",
    "  # `prefetch` lets the dataset fetch batches in the background while the model is training.\n",
    "  ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6206f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# preprocess training & validation sets\n",
    "ds_train = prepare_for_training(ds_train, batch_size=batch_size)\n",
    "ds_valid = prepare_for_training(ds_valid, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955cdbc9",
   "metadata": {},
   "source": [
    "### Model Definition <a name=\"model definition\"></a>\n",
    "\n",
    "  1. We use a base model (pretrained neural net for the imagenet challenge and specify that is trainable\n",
    "  2. We add a top model with a softmax classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27278760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE MODEL\n",
    "model_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_l/feature_vector/2\"\n",
    "# download & load the layer as a feature vector\n",
    "base_model = hub.KerasLayer(model_url, output_shape=[1280], trainable=True, name='base_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f8942",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  base_model,\n",
    "  tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"classification_layer\")\n",
    "])\n",
    "# build the model with input image shape as (64, 64, 3)\n",
    "model.build([None, 64, 64, 3])\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=\"adam\", \n",
    "    metrics=[\"accuracy\", tfa.metrics.F1Score(num_classes)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff21c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"satellite-classification\"\n",
    "model_path = os.path.join(\"../models\", model_name + \".h5\")\n",
    "if not os.path.exists(\"../models\"):\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012365b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the training & validation steps since we're using .repeat() on our dataset\n",
    "# number of training steps\n",
    "n_training_steps   = int(num_examples * 0.6) // batch_size\n",
    "# number of validation steps\n",
    "n_validation_steps = int(num_examples * 0.2) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62965e2d",
   "metadata": {},
   "source": [
    "### Model Training <a name=\"model training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8143fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=1\n",
    "epochs=5\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(model_path, save_best_only=True, verbose=1)\n",
    "# train the model\n",
    "history = model.fit(\n",
    "    train_ds, validation_data=valid_ds,\n",
    "    steps_per_epoch=n_training_steps,\n",
    "    validation_steps=n_validation_steps,\n",
    "    verbose=verbose, epochs=epochs, \n",
    "    callbacks=[model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae9a45b",
   "metadata": {},
   "source": [
    "### Model Evaluation <a name=\"model evaluation\"></a>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.14.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "source_map": [
   12,
   32,
   37,
   47,
   51,
   65,
   69,
   87,
   92,
   105,
   125,
   130,
   137,
   144,
   158,
   162,
   169,
   175,
   179,
   191
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}